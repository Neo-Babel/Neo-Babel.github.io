<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="NeoBabel: A novel multilingual image generation framework that sets a new Pareto frontier in performance, efficiency and inclusivity, supporting six languages: English, Chinese, Dutch, French, Hindi, and Persian.">
  <meta property="og:title" content="NeoBabel: A Multilingual Open Tower for Visual Generation"/>
  <meta property="og:description" content="NeoBabel sets a new Pareto frontier in multilingual image generation performance, efficiency, and inclusivity. We release an open toolkit, including all code, model checkpoints, and a curated dataset of 124M multilingual text-image pairs."/>
  <meta property="og:url" content="https://neobabel.github.io/"/>
  <meta property="og:image" content="static/images/neobabel_banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <meta name="twitter:title" content="NeoBabel: A Multilingual Open Tower for Visual Generation">
  <meta name="twitter:description" content="NeoBabel sets a new Pareto frontier in multilingual image generation performance, efficiency, and inclusivity.">
  <meta name="twitter:image" content="static/images/neobabel_twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Multilingual, Text-to-Image, Visual Generation, Generative AI, Open Source, Cross-Lingual, AI Inclusivity">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>NeoBabel: A Multilingual Open Tower for Visual Generation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- <style>
    .hero-background-container {
      background: linear-gradient(rgba(0, 0, 0, 0.4), rgba(0, 0, 0, 0.4)), url('static/images/neobabel-cohere-banner.png');
      background-size: cover;
      background-position: center center;
      background-repeat: no-repeat;
    }
    .hero-background-container .hero {
      background-color: transparent;
    }
    .hero-background-container .title,
    .hero-background-container .publication-authors,
    .hero-background-container .content.is-italic {
      color: white;
    }
    .hero-background-container .publication-authors span,
    .hero-background-container .eql-cntrb small {
      color: #dddddd;
    }
  </style> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<div class="hero-background-container">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <div class="is-flex is-justify-content-center is-vcentered">
                <img src="static/images/neobabel_new_color.png" alt="NeoBabel Icon" style="height: 1.8em; margin-right: 0.5em;">
                <span>NeoBabel: A Multilingual Open Tower for Visual Generation</span>
              </div>
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">Mohammad Mahdi Derakhshani<sup>2</sup>,</span>
              <span class="author-block">Dheeraj Varghese<sup>2</sup>,</span>
              <span class="author-block">Marzieh Fadaee<sup>1,†</sup>,</span>
              <span class="author-block">Cees G. M. Snoek<sup>2,†</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Cohere Labs, <sup>2</sup>University of Amsterdam</span>
              <span class="eql-cntrb"><small><br><sup>†</sup>Principal senior advisors</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" disabled title="Coming Soon!">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" disabled title="Coming Soon!">
                    <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" disabled title="Coming Soon!">
                    <span class="icon"><i class="fas fa-robot"></i></span><span>Models</span>
                  </a>
                </span>
              </div>
              <div class="publication-links">
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" disabled title="Coming Soon!">
                    <span class="icon"><i class="fas fa-database"></i></span><span>Pretraining Data</span>
                  </a>
                </span>
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" disabled title="Coming Soon!">
                    <span class="icon"><i class="fas fa-database"></i></span><span>Instruction Data</span>
                  </a>
                </span>
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" disabled title="Coming Soon!">
                    <span class="icon"><i class="fas fa-database"></i></span><span>Evaluation Data</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
</div>

  <!-- Hero Plot -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="static/images/geneval_demo_with_improvements.png" alt="Plot showing NeoBabel's performance compared to other models."/>
          <p class="content is-italic has-text-centered mt-2">
            NeoBabel establishes a new Pareto frontier in multilingual image generation performance, efficiency, and inclusivity. It matches state-of-the-art models on English benchmarks while being 2-4x smaller, and significantly outperforms them on multilingual tasks.
          </p>
        </div>
      </div>
    </div>
  </section>


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Text-to-image generation advancements have been predominantly English-centric, creating barriers for non-English speakers and perpetuating digital inequities. While existing systems rely on translation pipelines, these introduce semantic drift, computational overhead, and cultural misalignment. We introduce NEOBABEL, a novel multilingual image generation framework that sets a new Pareto frontier in performance, efficiency and inclusivity, supporting six languages: English, Chinese, Dutch, French, Hindi, and Persian. The model is trained using a combination of large-scale multilingual pretraining and high-resolution instruction tuning. To evaluate its capabilities, we expand two English-only benchmarks to multilingual equivalents: m-GenEval and m-DPG. NEOBABEL achieves state-of-the-art multilingual performance while retaining strong English capability. Notably, it performs on par with leading models on English tasks while outperforming them by +0.11 and +0.09 on multilingual benchmarks. We release an open toolkit, including all code, model checkpoints, a curated dataset of 124M multilingual text-image pairs, and standardized multilingual evaluation protocols, to advance inclusive AI research.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- NeoBabel Architecture -->
  <section class="section">
      <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">NeoBabel Architecture</h2>
          <div class="has-text-centered">
              <img src="static/images/architecture_diagram.png" alt="NeoBabel architecture diagram" style="max-width: 720px; width: 100%; margin: auto;"/>
              <p class="is-italic mt-2">Overview of the NeoBabel architecture.</p>
          </div>
          <div class="content mt-5">
              <p>NeoBabel builds upon a pretrained multilingual LLM (Gemma-2) and introduces two key modifications for visual generation:</p>
              <ul>
                  <li><strong>Unified Multimodal Embedding:</strong> We extend the LLM's vocabulary with 8,192 new embeddings for discrete image tokens. This allows the model to process both text and image tokens natively within a shared semantic space, eliminating the need for separate encoders.</li>
                  <li><strong>Modality-Aware Attention:</strong> A hybrid attention mechanism is used. Text tokens use causal attention to preserve autoregressive language capabilities, while image tokens use full bidirectional attention for rich, high-fidelity image synthesis.</li>
                  <li><strong>Unified Task Representation:</strong> All tasks, such as text-to-image generation and inpainting, are treated as a single autoregressive sequence prediction problem, simplifying the training pipeline.</li>
              </ul>
          </div>
      </div>
  </section>

  <!-- NeoBabel Multilingual Datasets -->
  <section class="section hero is-light">
      <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">NeoBabel Multilingual Datasets</h2>
          <div class="content has-text-justified">
              <p>
                  A primary challenge in multilingual generation is the scarcity of high-quality, culturally annotated visual-linguistic data. To address this, we developed a comprehensive data curation pipeline to expand existing English-only datasets into six target languages: English, Chinese, Dutch, French, Hindi, and Persian. Our process involves:
              </p>
              <ol>
                  <li><strong>Recaptioning:</strong> Generating detailed, high-quality English captions for images using a powerful vision-language model (InternVL).</li>
                  <li><strong>Quality Filtering:</strong> Applying a multi-step filtering process to ensure captions are of appropriate length, are in the correct language, align with the visual content, and are free of toxic or NSFW material.</li>
                  <li><strong>Translation:</strong> Translating the high-quality English captions into the five other target languages using state-of-the-art translation models (NLLB and Gemini).</li>
              </ol>
              <p>This pipeline expanded our total dataset from 39 million to <strong>124 million</strong> multilingual text-image pairs.</p>
              <div class="table-container">
                  <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                      <thead>
                          <tr><th>Original Dataset</th><th>Image Source</th><th>Original Size</th><th>Expansion Method</th><th>New Size (6 Langs)</th></tr>
                      </thead>
                      <tbody>
                          <tr><td>ImageNet 1K</td><td>Web</td><td>1M</td><td>Translation</td><td>6M</td></tr>
                          <tr><td>CC12M</td><td>Web</td><td>12M</td><td>Recaptioning</td><td>12M (Eng only)</td></tr>
                          <tr><td>SA-1B</td><td>Photography</td><td>10M</td><td>Recaptioning</td><td>10M (Eng only)</td></tr>
                          <tr><td>LAION-Aesthetic</td><td>Web</td><td>12M</td><td>Recaption + Translation</td><td>72M</td></tr>
                          <tr><td>JourneyDB</td><td>Synthetic</td><td>4M</td><td>Recaption + Translation</td><td>24M</td></tr>
                          <tr><td>BLIP3-o Instruct</td><td>Web + Synthetic</td><td>60K</td><td>Translation</td><td>360K</td></tr>
                          <tr><td><strong>Total</strong></td><td>-</td><td><strong>39M</strong></td><td>-</td><td><strong>124M</strong></td></tr>
                      </tbody>
                  </table>
              </div>
              <p class="has-text-centered is-italic">Expansion of datasets for multilingual training.</p>
          </div>
      </div>
  </section>

  <!-- NeoBabel Training Stages -->
  <section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">NeoBabel Training Stages</h2>
        <div class="has-text-centered">
            <img src="static/images/progressive-training-merged.png" alt="Graph showing performance improvement across training stages." style="max-width: 800px; width: 100%; margin: auto;"/>
            <p class="is-italic mt-2">Performance on m-GenEval and m-DPG improves steadily across pretraining and instruction tuning stages.</p>
        </div>
        <div class="content mt-5">
            <p>NeoBabel is trained using a staged learning framework that progressively builds its capabilities:</p>
            <div class="columns">
                <div class="column">
                    <p><strong>Progressive Pretraining (at 256x256):</strong></p>
                    <ul>
                        <li><strong>Stage 1 - Pixel Dependency Learning:</strong> Training on ImageNet with class labels to learn foundational visual representations.</li>
                        <li><strong>Stage 2 - Scaling Alignment:</strong> Fine-tuning on 94M image-caption pairs to ground the model in natural language.</li>
                        <li><strong>Stage 3 - Refined Multilingual Pretraining:</strong> Final pretraining on 96M high-quality pairs to improve aesthetic generation.</li>
                    </ul>
                </div>
                <div class="column">
                    <p><strong>Progressive Instruction Tuning (at 512x512):</strong></p>
                    <ul>
                        <li><strong>Stage 1 - Initial Alignment:</strong> Training on a mix of aesthetic and instruction-following data to build high-resolution capabilities.</li>
                        <li><strong>Stage 2 - Instruction Refinement:</strong> Shifting the data mix to emphasize complex, instruction-rich samples to refine the model's ability to follow commands.</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
  </section>

  <!-- Multilingual Evaluation -->
  <section class="section hero is-light">
      <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">Multilingual Evaluation</h2>
          <div class="content has-text-justified">
              <p>
                  Existing image generation benchmarks are overwhelmingly English-centric. To properly assess NeoBabel, we created a comprehensive multilingual evaluation suite.
              </p>
              <ul>
                  <li><strong>Multilingual Benchmarks:</strong> We extended two popular English-only benchmarks by translating their prompts into our five other target languages, creating <strong>m-GenEval</strong> (for compositional reasoning) and <strong>m-DPG</strong> (for general-purpose generation).</li>
                  <li><strong>New Evaluation Metrics:</strong> We introduced two novel metrics to measure multilingual consistency:
                      <ul>
                          <li><strong>Cross-Lingual Consistency (CLC):</strong> Measures how visually similar the generated images are for the same prompt across different languages. A high CLC score indicates the model has a consistent internal representation of concepts, regardless of language.</li>
                          <li><strong>Code-Switching Similarity (CSS):</strong> Assesses the model's robustness to prompts that mix multiple languages within a single sentence, a common real-world scenario.</li>
                      </ul>
                  </li>
              </ul>
              <p>This new suite allows for a more rigorous and realistic evaluation of a model's true multilingual capabilities.</p>
          </div>
      </div>
  </section>

  <!-- Qualitative Results -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Qualitative Results</h2>
      
      <h3 class="title is-4 has-text-centered">Multilingual Generation</h3>
      <p class="has-text-centered content">NeoBabel produces semantically accurate and visually cohesive outputs for the same concept across all six supported languages. Below are examples where the English prompt was translated, and one image was generated for each language.</p>
      <div class="columns is-centered">
        <div class="column">
          <img src="static/images/qual_abstract_cube.png" alt="A vibrant, melting abstract cube generated in 6 languages.">
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column">
          <img src="static/images/qual_cat.png" alt="An animated cat character wearing a hat, generated in 6 languages.">
        </div>
      </div>

      <h3 class="title is-4 has-text-centered mt-6">Multilingual Inpainting & Extrapolation</h3>
      <p class="has-text-centered content">The model can edit and extend images using prompts in various languages without additional fine-tuning.</p>
      <div class="columns is-centered is-vcentered">
        <div class="column">
          <img src="static/images/inpainting_chair.png" alt="Inpainting a chair to look like a strawberry in Chinese.">
          <p class="has-text-centered is-italic">Inpainting across languages.</p>
        </div>
        <div class="column">
          <img src="static/images/extrapolation_car.png" alt="Extrapolating a futuristic car in a city of mirrors using English and Hindi prompts.">
          <p class="has-text-centered is-italic">Extrapolation across languages.</p>
        </div>
      </div>

      <h3 class="title is-4 has-text-centered mt-6">Cross-Lingual (Code-Switched) Prompt Generation</h3>
      <p class="has-text-centered content">A challenging test where a single prompt contains phrases from multiple languages. NeoBabel successfully integrates these multilingual instructions into a single, coherent image.</p>
      <div class="columns is-centered is-vcentered">
        <div class="column is-half">
          <img src="static/images/codeswitch_corgi.png" alt="A Corgi dog wearing sunglasses, generated from an English, Dutch, and French prompt.">
          <p class="has-text-centered is-italic">Generated from a mix of English, Dutch, and French.</p>
        </div>
        <div class="column is-half">
          <img src="static/images/codeswitch_smugcat.png" alt="A smug cat wearing sunglasses, generated from a Hindi, Persian, and Chinese prompt.">
          <p class="has-text-centered is-italic">Generated from a mix of Hindi, Persian, and Chinese.</p>
        </div>
      </div>
    </div>
  </section>

  <!-- Results Tables -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Quantitative Results</h2>
        <p class="content has-text-centered">NeoBabel achieves state-of-the-art results on both English and multilingual benchmarks, despite being 2-4x smaller than competing models.</p>
        
        <h3 class="title is-4 has-text-centered">Multilingual m-GenEval Benchmark</h3>
        <div class="columns is-centered">
          <div class="column is-full">
            <img src="static/images/model_performance_faceted_heatmap_colorbar.png" alt="Model Performance Heatmap on m-GenEval" class="image">
            <p class="has-text-centered is-italic mt-2">Figure 3 from the paper: NeoBabel matches the SOTA English score and outperforms on all multilingual cases.</p>
          </div>
        </div>
      

        <h3 class="title is-4 has-text-centered mt-6">Multilingual m-DPG Benchmark</h3>
        <div class="table-container">
          <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <thead>
                  <tr><th>Method</th><th>Params.</th><th>English</th><th>Chinese</th><th>Dutch</th><th>French</th><th>Hindi</th><th>Persian</th><th><strong>Overall</strong></th></tr>
              </thead>
              <tbody>
                  <tr><td>Show-o</td><td>1.3B</td><td>0.67</td><td>0.10</td><td>0.22</td><td>0.32</td><td>0.04</td><td>0.04</td><td>0.23</td></tr>
                  <tr><td>BLIP3-o</td><td>4B</td><td>0.79</td><td>0.60</td><td>0.58</td><td>0.59</td><td>0.47</td><td>0.49</td><td>0.58</td></tr>
                  <tr><td>Janus Pro</td><td>7B</td><td>0.84</td><td>0.50</td><td>0.61</td><td>0.68</td><td>0.12</td><td>0.12</td><td>0.47</td></tr>
                  <tr><td>BLIP3-o</td><td>8B</td><td>0.80</td><td>0.56</td><td>0.59</td><td>0.61</td><td>0.50</td><td>0.53</td><td>0.59</td></tr>
                  <tr><td><strong>NeoBabel (Ours)</strong></td><td><strong>2B</strong></td><td><strong>0.75</strong></td><td><strong>0.70</strong></td><td><strong>0.69</strong></td><td><strong>0.70</strong></td><td><strong>0.63</strong></td><td><strong>0.65</strong></td><td><strong>0.68</strong></td></tr>
              </tbody>
          </table>
          <p class="has-text-centered is-italic">Table 3 from the paper: NeoBabel significantly outperforms all baselines across non-English languages.</p>
        </div>
    </div>
  </section>

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>To be determined.</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>